{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing Steps\n",
    "**Spike removal / filtering methods**\n",
    "<br>\n",
    "    -- Reduction of spike events by special design of the instrument (Zhao, 2003)\n",
    "<br>\n",
    "    -- Automatic Spike Removal Algorithm for Raman Spectra: wavelet transform (spike removal raman filter from matlab)\n",
    "<br>\n",
    "    -- Missing point polynomial filter (I have the code)\n",
    "<br>\n",
    "    -- Robust smoothing filter\n",
    "<br>\n",
    "    -- Moving window filter \n",
    "<br>\n",
    "**Remove background Autofluorescence noise**\n",
    "<br>\n",
    "--IModPoly (Chad A Lieber and Anita Mahadevan-Jansen. Automated method for subtraction offluorescence from biological raman spectra.Applied spectroscopy, 57(11):1363â€“1367,2003) (https://github.com/michaelstchen/modPolyFit)(Faster technique)\n",
    " <br>\n",
    "--Zhiming Zhang (An intelligent background-correction algorithm for highly fluorescent samples in raman spectroscopy: https://onlinelibrary.wiley.com/doi/abs/10.1002/jrs.2500)(https://github.com/zmzhang/baselineWavelet)\n",
    "<br>\n",
    "--Vancouver Raman Algorithm (Jianhua Zhao: http://journals.sagepub.com/doi/abs/10.1366/000370207782597003) \n",
    "<br>\n",
    "--EMD (Empirical  Mode Decomposition) (https://github.com/laszukdawid/PyEMD)\n",
    "<br>\n",
    "**Smoothing (Denoising)**\n",
    "<br>\n",
    "-- Savisky-Golay filtering (Scipi package):  https://github.com/scipy/scipy/blob/master/scipy/signal/_savitzky_golay.py\n",
    "<br>\n",
    "-- Moving Average/median\n",
    "<br>\n",
    "--CARS (Coherent Anti-Stokes Raman spectroscopy) \n",
    "<br>\n",
    "**Normalize**\n",
    "<br>\n",
    "--Min/Max method (I have the code).\n",
    "<br>\n",
    "--Vector based \n",
    "<br>\n",
    "**Spectral and intensity re-calibration**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Normal**\n",
    "<br>\n",
    "Individual patients with 5 sample points in blood is 471\n",
    "<br>\n",
    "Individual patients with 3 sample points in blood is 228"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Disease 1:**\n",
    "\n",
    "Individual patients with 5 sample points in blood is 153.\n",
    "<br>\n",
    "Individual patients with 3 sample points in blood is 20.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/titli/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Class dealing with the Raman data\n",
    "'''\n",
    "import sys\n",
    "import numpy as np\n",
    "np.set_printoptions(threshold=sys.maxsize)\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import random\n",
    "import os\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "matplotlib.use('Qt5Agg')\n",
    "import matplotlib.pyplot as plt\n",
    "from convertwdf import *\n",
    "from wdfReader import * \n",
    "from scipy import sparse\n",
    "from scipy.sparse.linalg import spsolve\n",
    "from sklearn import preprocessing\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from keras.utils import to_categorical\n",
    "from keras.layers import Dense, Dropout, Activation, Input, BatchNormalization, MaxPooling1D, Bidirectional,LSTM\n",
    "from keras.layers import Conv1D, GlobalMaxPooling1D, MaxPool1D, Flatten , Embedding, GlobalMaxPool1D\n",
    "from keras.models import Model\n",
    "from keras.optimizers import SGD, Adam, rmsprop\n",
    "#%matplotlib inline \n",
    "#https://github.com/MacDumi/Deconvolution\n",
    "#python3 Deconvolution_test.py /home/titli/Documents/Deconvolution-master/0151.txt \n",
    "#https://www.pnas.org/content/114/31/8247"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(data):\n",
    "    _min = np.min(data)\n",
    "    _max = np.max(data)\n",
    "    return (data - _min) / (_max - _min)\n",
    "def getspikes(fileID):\n",
    "    \n",
    "    x_data= fileID.get_xdata()\n",
    "    spectra= fileID.get_spectra()\n",
    "    return (x_data, spectra)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "patient_array_1 = [] #patients in disease1\n",
    "patient_array_0 = [] #patients in disease0\n",
    "spectra_array0 = [] #spectrum in disease0\n",
    "spectra_array1 = [] #spectrum in disease1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Disease 1\n",
    "rootdir = '/home/titli/Documents/disease1'\n",
    "for subdir, dirs, files in os.walk(rootdir):\n",
    "    for file in files:\n",
    "        #print (os.path.join(subdir, file))\n",
    "        txt = os.path.join(subdir, file)\n",
    "        x = txt.split(\"/\")\n",
    "        if( x[5] == '1_0-5-1' and x[8] == '980'):\n",
    "            if (str(x[7]) not in patient_array_1):\n",
    "                patient_array_1.append(x[7])\n",
    "                wdfIle = wdfReader(os.path.join(subdir, file))\n",
    "                X, spectra = getspikes(wdfIle) # plotting the spectrum\n",
    "                #if len(spectra)<1015:\n",
    "                #    spectra[len(spectra):len(spectra)+(1015-len(spectra))]=10000\n",
    "                spectra = normalize(spectra)\n",
    "                spectra_array1.append(spectra)\n",
    "spectra_array_1= pd.DataFrame(spectra_array1)\n",
    "labels_1 = pd.DataFrame({'labels': np.ones((len(spectra_array1),), dtype=int)})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normal patients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "rootdir = '/home/titli/Documents/normal'\n",
    "for subdir, dirs, files in os.walk(rootdir):\n",
    "    for file in files:\n",
    "        #print (os.path.join(subdir, file))\n",
    "        txt = os.path.join(subdir, file)\n",
    "        x = txt.split(\"/\")\n",
    "        if( x[5] == '1_0-5-1' and x[8] == '980'):\n",
    "            if (str(x[7]) not in patient_array_0):\n",
    "                patient_array_0.append(x[7])\n",
    "                wdfIle = wdfReader(os.path.join(subdir, file))\n",
    "                X, spectra = getspikes(wdfIle) # plotting the spectrum\n",
    "                #if len(spectra)<1015:\n",
    "                #    spectra[len(spectra):len(spectra)+(1015-len(spectra))]=10000\n",
    "                spectra = normalize(spectra)\n",
    "                spectra_array0.append(spectra)\n",
    "spectra_array_0= pd.DataFrame(spectra_array0)\n",
    "labels_0 = pd.DataFrame({'labels': np.zeros((len(spectra_array0),), dtype=int)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>1005</th>\n",
       "      <th>1006</th>\n",
       "      <th>1007</th>\n",
       "      <th>1008</th>\n",
       "      <th>1009</th>\n",
       "      <th>1010</th>\n",
       "      <th>1011</th>\n",
       "      <th>1012</th>\n",
       "      <th>1013</th>\n",
       "      <th>1014</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.011308</td>\n",
       "      <td>0.006305</td>\n",
       "      <td>0.008163</td>\n",
       "      <td>0.010361</td>\n",
       "      <td>0.000854</td>\n",
       "      <td>0.010665</td>\n",
       "      <td>0.006273</td>\n",
       "      <td>0.005631</td>\n",
       "      <td>0.010779</td>\n",
       "      <td>0.010136</td>\n",
       "      <td>...</td>\n",
       "      <td>0.410484</td>\n",
       "      <td>0.409580</td>\n",
       "      <td>0.404766</td>\n",
       "      <td>0.403591</td>\n",
       "      <td>0.406505</td>\n",
       "      <td>0.406420</td>\n",
       "      <td>0.415236</td>\n",
       "      <td>0.417964</td>\n",
       "      <td>0.416877</td>\n",
       "      <td>0.408439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.018628</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.008605</td>\n",
       "      <td>0.006683</td>\n",
       "      <td>0.010225</td>\n",
       "      <td>0.011337</td>\n",
       "      <td>0.004359</td>\n",
       "      <td>0.016999</td>\n",
       "      <td>0.015077</td>\n",
       "      <td>0.016996</td>\n",
       "      <td>...</td>\n",
       "      <td>0.702732</td>\n",
       "      <td>0.710878</td>\n",
       "      <td>0.698623</td>\n",
       "      <td>0.721818</td>\n",
       "      <td>0.683514</td>\n",
       "      <td>0.697643</td>\n",
       "      <td>0.698664</td>\n",
       "      <td>0.716016</td>\n",
       "      <td>0.717518</td>\n",
       "      <td>0.708675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.009522</td>\n",
       "      <td>0.013726</td>\n",
       "      <td>0.009025</td>\n",
       "      <td>0.010740</td>\n",
       "      <td>0.008650</td>\n",
       "      <td>0.007976</td>\n",
       "      <td>0.002351</td>\n",
       "      <td>0.001546</td>\n",
       "      <td>0.003438</td>\n",
       "      <td>0.000512</td>\n",
       "      <td>...</td>\n",
       "      <td>0.135977</td>\n",
       "      <td>0.136347</td>\n",
       "      <td>0.133178</td>\n",
       "      <td>0.133158</td>\n",
       "      <td>0.132856</td>\n",
       "      <td>0.134464</td>\n",
       "      <td>0.131475</td>\n",
       "      <td>0.137076</td>\n",
       "      <td>0.136278</td>\n",
       "      <td>0.140992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.001365</td>\n",
       "      <td>0.006520</td>\n",
       "      <td>0.004609</td>\n",
       "      <td>0.014125</td>\n",
       "      <td>0.011093</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.014213</td>\n",
       "      <td>0.017899</td>\n",
       "      <td>0.018674</td>\n",
       "      <td>0.006022</td>\n",
       "      <td>...</td>\n",
       "      <td>0.743194</td>\n",
       "      <td>0.731239</td>\n",
       "      <td>0.735599</td>\n",
       "      <td>0.732072</td>\n",
       "      <td>0.732309</td>\n",
       "      <td>0.750455</td>\n",
       "      <td>0.741198</td>\n",
       "      <td>0.742148</td>\n",
       "      <td>0.743993</td>\n",
       "      <td>0.741006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.013971</td>\n",
       "      <td>0.010878</td>\n",
       "      <td>0.010359</td>\n",
       "      <td>0.010013</td>\n",
       "      <td>0.010440</td>\n",
       "      <td>0.007218</td>\n",
       "      <td>0.006186</td>\n",
       "      <td>0.002451</td>\n",
       "      <td>0.006826</td>\n",
       "      <td>0.003864</td>\n",
       "      <td>...</td>\n",
       "      <td>0.173007</td>\n",
       "      <td>0.180340</td>\n",
       "      <td>0.175647</td>\n",
       "      <td>0.175660</td>\n",
       "      <td>0.176670</td>\n",
       "      <td>0.181112</td>\n",
       "      <td>0.177315</td>\n",
       "      <td>0.181686</td>\n",
       "      <td>0.179331</td>\n",
       "      <td>0.181814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.004867</td>\n",
       "      <td>0.000776</td>\n",
       "      <td>0.003694</td>\n",
       "      <td>0.003351</td>\n",
       "      <td>0.000757</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001671</td>\n",
       "      <td>0.002809</td>\n",
       "      <td>0.000513</td>\n",
       "      <td>0.004965</td>\n",
       "      <td>...</td>\n",
       "      <td>0.158370</td>\n",
       "      <td>0.153636</td>\n",
       "      <td>0.163266</td>\n",
       "      <td>0.158154</td>\n",
       "      <td>0.160056</td>\n",
       "      <td>0.163236</td>\n",
       "      <td>0.159264</td>\n",
       "      <td>0.165093</td>\n",
       "      <td>0.167228</td>\n",
       "      <td>0.162265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.009930</td>\n",
       "      <td>0.007167</td>\n",
       "      <td>0.006735</td>\n",
       "      <td>0.010690</td>\n",
       "      <td>0.007388</td>\n",
       "      <td>0.005603</td>\n",
       "      <td>0.000950</td>\n",
       "      <td>0.003983</td>\n",
       "      <td>0.005012</td>\n",
       "      <td>0.006907</td>\n",
       "      <td>...</td>\n",
       "      <td>0.159082</td>\n",
       "      <td>0.158425</td>\n",
       "      <td>0.161016</td>\n",
       "      <td>0.166725</td>\n",
       "      <td>0.167105</td>\n",
       "      <td>0.167356</td>\n",
       "      <td>0.170549</td>\n",
       "      <td>0.174000</td>\n",
       "      <td>0.174724</td>\n",
       "      <td>0.179297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.010439</td>\n",
       "      <td>0.013195</td>\n",
       "      <td>0.006978</td>\n",
       "      <td>0.007971</td>\n",
       "      <td>0.010553</td>\n",
       "      <td>0.003387</td>\n",
       "      <td>0.007133</td>\n",
       "      <td>0.001136</td>\n",
       "      <td>0.006470</td>\n",
       "      <td>0.001639</td>\n",
       "      <td>...</td>\n",
       "      <td>0.412738</td>\n",
       "      <td>0.409432</td>\n",
       "      <td>0.415960</td>\n",
       "      <td>0.418079</td>\n",
       "      <td>0.408418</td>\n",
       "      <td>0.420618</td>\n",
       "      <td>0.418415</td>\n",
       "      <td>0.416212</td>\n",
       "      <td>0.417904</td>\n",
       "      <td>0.428737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.017110</td>\n",
       "      <td>0.004732</td>\n",
       "      <td>0.004036</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.006852</td>\n",
       "      <td>0.007640</td>\n",
       "      <td>0.009665</td>\n",
       "      <td>0.005383</td>\n",
       "      <td>0.005801</td>\n",
       "      <td>0.006712</td>\n",
       "      <td>...</td>\n",
       "      <td>0.431166</td>\n",
       "      <td>0.434050</td>\n",
       "      <td>0.435448</td>\n",
       "      <td>0.431997</td>\n",
       "      <td>0.438242</td>\n",
       "      <td>0.430738</td>\n",
       "      <td>0.425313</td>\n",
       "      <td>0.429479</td>\n",
       "      <td>0.423365</td>\n",
       "      <td>0.427529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.015331</td>\n",
       "      <td>0.012443</td>\n",
       "      <td>0.008660</td>\n",
       "      <td>0.007925</td>\n",
       "      <td>0.016812</td>\n",
       "      <td>0.014313</td>\n",
       "      <td>0.019828</td>\n",
       "      <td>0.012842</td>\n",
       "      <td>0.024764</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.662620</td>\n",
       "      <td>0.666214</td>\n",
       "      <td>0.659030</td>\n",
       "      <td>0.656851</td>\n",
       "      <td>0.652109</td>\n",
       "      <td>0.662239</td>\n",
       "      <td>0.651602</td>\n",
       "      <td>0.668007</td>\n",
       "      <td>0.650072</td>\n",
       "      <td>0.663011</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows Ã— 1015 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       0         1         2         3         4         5         6     \\\n",
       "0  0.011308  0.006305  0.008163  0.010361  0.000854  0.010665  0.006273   \n",
       "1  0.018628  0.000000  0.008605  0.006683  0.010225  0.011337  0.004359   \n",
       "2  0.009522  0.013726  0.009025  0.010740  0.008650  0.007976  0.002351   \n",
       "3  0.001365  0.006520  0.004609  0.014125  0.011093  0.000000  0.014213   \n",
       "4  0.013971  0.010878  0.010359  0.010013  0.010440  0.007218  0.006186   \n",
       "5  0.004867  0.000776  0.003694  0.003351  0.000757  0.000000  0.001671   \n",
       "6  0.009930  0.007167  0.006735  0.010690  0.007388  0.005603  0.000950   \n",
       "7  0.010439  0.013195  0.006978  0.007971  0.010553  0.003387  0.007133   \n",
       "8  0.017110  0.004732  0.004036  0.000000  0.006852  0.007640  0.009665   \n",
       "9  0.015331  0.012443  0.008660  0.007925  0.016812  0.014313  0.019828   \n",
       "\n",
       "       7         8         9       ...         1005      1006      1007  \\\n",
       "0  0.005631  0.010779  0.010136    ...     0.410484  0.409580  0.404766   \n",
       "1  0.016999  0.015077  0.016996    ...     0.702732  0.710878  0.698623   \n",
       "2  0.001546  0.003438  0.000512    ...     0.135977  0.136347  0.133178   \n",
       "3  0.017899  0.018674  0.006022    ...     0.743194  0.731239  0.735599   \n",
       "4  0.002451  0.006826  0.003864    ...     0.173007  0.180340  0.175647   \n",
       "5  0.002809  0.000513  0.004965    ...     0.158370  0.153636  0.163266   \n",
       "6  0.003983  0.005012  0.006907    ...     0.159082  0.158425  0.161016   \n",
       "7  0.001136  0.006470  0.001639    ...     0.412738  0.409432  0.415960   \n",
       "8  0.005383  0.005801  0.006712    ...     0.431166  0.434050  0.435448   \n",
       "9  0.012842  0.024764  0.000000    ...     0.662620  0.666214  0.659030   \n",
       "\n",
       "       1008      1009      1010      1011      1012      1013      1014  \n",
       "0  0.403591  0.406505  0.406420  0.415236  0.417964  0.416877  0.408439  \n",
       "1  0.721818  0.683514  0.697643  0.698664  0.716016  0.717518  0.708675  \n",
       "2  0.133158  0.132856  0.134464  0.131475  0.137076  0.136278  0.140992  \n",
       "3  0.732072  0.732309  0.750455  0.741198  0.742148  0.743993  0.741006  \n",
       "4  0.175660  0.176670  0.181112  0.177315  0.181686  0.179331  0.181814  \n",
       "5  0.158154  0.160056  0.163236  0.159264  0.165093  0.167228  0.162265  \n",
       "6  0.166725  0.167105  0.167356  0.170549  0.174000  0.174724  0.179297  \n",
       "7  0.418079  0.408418  0.420618  0.418415  0.416212  0.417904  0.428737  \n",
       "8  0.431997  0.438242  0.430738  0.425313  0.429479  0.423365  0.427529  \n",
       "9  0.656851  0.652109  0.662239  0.651602  0.668007  0.650072  0.663011  \n",
       "\n",
       "[10 rows x 1015 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spectra_array_0.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_df = pd.concat([spectra_array_0,spectra_array_1], axis = 0)\n",
    "total_df.fillna(1e-5)\n",
    "#too many zeros replace with a min value of 1e-4 to avoid nan in loss function\n",
    "total_df = total_df.apply(lambda x: [y if y <= 1e-5 else 1e-4 for y in x])\n",
    "labels_df = pd.concat([labels_0,labels_1], axis = 0)\n",
    "indices=list(range(0,len(total_df)))\n",
    "random.shuffle(indices)\n",
    "X = total_df.values[indices]\n",
    "y = labels_df.values[indices]\n",
    "#\n",
    "#len(total_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test- Train Dataset: Making a balanced dataset 50 disease1 and 50 normal\n",
    "split_val= int(len(X)*0.8)\n",
    "X_train=X[:split_val]\n",
    "X_test=X[split_val:,]\n",
    "y_train =y[:split_val]\n",
    "y_test =y[split_val:]\n",
    "X_train = X_train.reshape(X_train.shape[0],X_train.shape[1],1)\n",
    "X_test = X_test.reshape(X_test.shape[0],X_test.shape[1],1)\n",
    "# Convert labels to categorical one-hot encoding\n",
    "y_train_labels = to_categorical(y_train, num_classes=2)\n",
    "y_test_labels = to_categorical(y_test, num_classes=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kraub_method():\n",
    "    inp =  Input(shape=(1015, 1))\n",
    "    x = Conv1D(32, kernel_size = 7, strides= 1,padding='valid', activation='relu')(inp)\n",
    "    x = Conv1D(16, kernel_size = 5, strides= 1, padding='valid', activation='relu')(x)\n",
    "    x = Flatten()(x)\n",
    "    x = Dropout(0.01)(x)\n",
    "    x = Dense(256, activation='relu')(x)\n",
    "    x = Dropout(0.01)(x)\n",
    "    x = Dense(256, activation='relu')(x)\n",
    "    preds = Dense(2, activation='softmax')(x)\n",
    "    model = Model(inp, preds)\n",
    "    model.compile(loss= 'categorical_crossentropy',\n",
    "              optimizer= 'Adam',\n",
    "              metrics=['acc'])\n",
    "    return model\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/titli/anaconda3/lib/python3.6/site-packages/keras/callbacks.py:1065: UserWarning: `epsilon` argument is deprecated and will be removed, use `min_delta` instead.\n",
      "  warnings.warn('`epsilon` argument is deprecated and '\n"
     ]
    }
   ],
   "source": [
    "from keras.callbacks import ModelCheckpoint, LearningRateScheduler, EarlyStopping, ReduceLROnPlateau\n",
    "weight_path=\"{}_model_step2.hdf5\".format('boat_detector')\n",
    "checkpoint = ModelCheckpoint(weight_path, monitor='val_loss', verbose=1, \n",
    "                             save_best_only=True, mode='min', save_weights_only = True)\n",
    "\n",
    "reduceLROnPlat = ReduceLROnPlateau(monitor='val_loss', factor=0.8, patience=10, verbose=1, mode='auto', epsilon=0.0001, cooldown=5, min_lr=0.0001)\n",
    "early = EarlyStopping(monitor=\"val_loss\", \n",
    "                      mode=\"min\", \n",
    "                      patience=10) \n",
    "callbacks_list = [checkpoint, early, reduceLROnPlat]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 420 samples, validate on 105 samples\n",
      "Epoch 1/65\n",
      "420/420 [==============================] - 4s 10ms/step - loss: 0.6075 - acc: 0.7167 - val_loss: 0.6700 - val_acc: 0.7048\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.66998, saving model to boat_detector_model_step2.hdf5\n",
      "Epoch 2/65\n",
      "420/420 [==============================] - 3s 8ms/step - loss: 0.6023 - acc: 0.7310 - val_loss: 0.6073 - val_acc: 0.7048\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.66998 to 0.60731, saving model to boat_detector_model_step2.hdf5\n",
      "Epoch 3/65\n",
      "420/420 [==============================] - 3s 8ms/step - loss: 0.5887 - acc: 0.7310 - val_loss: 0.6131 - val_acc: 0.7048\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.60731\n",
      "Epoch 4/65\n",
      "420/420 [==============================] - 3s 8ms/step - loss: 0.5968 - acc: 0.7310 - val_loss: 0.6218 - val_acc: 0.7048\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.60731\n",
      "Epoch 5/65\n",
      "420/420 [==============================] - 3s 8ms/step - loss: 0.5850 - acc: 0.7310 - val_loss: 0.6425 - val_acc: 0.7048\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.60731\n",
      "Epoch 6/65\n",
      "420/420 [==============================] - 4s 8ms/step - loss: 0.5892 - acc: 0.7310 - val_loss: 0.6163 - val_acc: 0.7048\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.60731\n",
      "Epoch 7/65\n",
      "420/420 [==============================] - 4s 9ms/step - loss: 0.6014 - acc: 0.7310 - val_loss: 0.6069 - val_acc: 0.7048\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.60731 to 0.60690, saving model to boat_detector_model_step2.hdf5\n",
      "Epoch 8/65\n",
      "420/420 [==============================] - 4s 9ms/step - loss: 0.5875 - acc: 0.7310 - val_loss: 0.6074 - val_acc: 0.7048\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.60690\n",
      "Epoch 9/65\n",
      "420/420 [==============================] - 3s 8ms/step - loss: 0.5854 - acc: 0.7310 - val_loss: 0.6086 - val_acc: 0.7048\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.60690\n",
      "Epoch 10/65\n",
      "420/420 [==============================] - 3s 8ms/step - loss: 0.5889 - acc: 0.7310 - val_loss: 0.6118 - val_acc: 0.7048\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.60690\n",
      "Epoch 11/65\n",
      "420/420 [==============================] - 4s 9ms/step - loss: 0.5856 - acc: 0.7310 - val_loss: 0.6069 - val_acc: 0.7048\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.60690 to 0.60685, saving model to boat_detector_model_step2.hdf5\n",
      "Epoch 12/65\n",
      "420/420 [==============================] - 4s 9ms/step - loss: 0.5847 - acc: 0.7310 - val_loss: 0.6085 - val_acc: 0.7048\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.60685\n",
      "Epoch 13/65\n",
      "420/420 [==============================] - 4s 9ms/step - loss: 0.5852 - acc: 0.7310 - val_loss: 0.6080 - val_acc: 0.7048\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.60685\n",
      "Epoch 14/65\n",
      "420/420 [==============================] - 4s 9ms/step - loss: 0.5865 - acc: 0.7310 - val_loss: 0.6069 - val_acc: 0.7048\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.60685\n",
      "Epoch 15/65\n",
      "420/420 [==============================] - 4s 9ms/step - loss: 0.5832 - acc: 0.7310 - val_loss: 0.6086 - val_acc: 0.7048\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.60685\n",
      "Epoch 16/65\n",
      "420/420 [==============================] - 3s 8ms/step - loss: 0.5851 - acc: 0.7310 - val_loss: 0.6124 - val_acc: 0.7048\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.60685\n",
      "Epoch 17/65\n",
      "420/420 [==============================] - 3s 8ms/step - loss: 0.5840 - acc: 0.7310 - val_loss: 0.6078 - val_acc: 0.7048\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.60685\n",
      "\n",
      "Epoch 00017: ReduceLROnPlateau reducing learning rate to 0.000800000037997961.\n",
      "Epoch 18/65\n",
      "420/420 [==============================] - 3s 8ms/step - loss: 0.5839 - acc: 0.7310 - val_loss: 0.6082 - val_acc: 0.7048\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.60685\n",
      "Epoch 19/65\n",
      "420/420 [==============================] - 3s 8ms/step - loss: 0.5835 - acc: 0.7310 - val_loss: 0.6084 - val_acc: 0.7048\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.60685\n",
      "Epoch 20/65\n",
      "420/420 [==============================] - 4s 8ms/step - loss: 0.5835 - acc: 0.7310 - val_loss: 0.6088 - val_acc: 0.7048\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.60685\n",
      "Epoch 21/65\n",
      "420/420 [==============================] - 4s 9ms/step - loss: 0.5838 - acc: 0.7310 - val_loss: 0.6079 - val_acc: 0.7048\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 0.60685\n"
     ]
    }
   ],
   "source": [
    "model = kraub_method()\n",
    "history = model.fit(X_train, y_train_labels, batch_size= 10, epochs=65, validation_data=(X_test, y_test_labels),callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to disk\n"
     ]
    }
   ],
   "source": [
    "model_json = model.to_json()\n",
    "with open(\"model_step1.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "# serialize weights to HDF5\n",
    "model.save_weights(\"model_step1.h5\")\n",
    "print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "patient_array_1 = [] #patients in disease1\n",
    "patient_array_0 = [] #patients in disease0\n",
    "spectra_array0 = [] #spectrum in disease0\n",
    "spectra_array1 = [] #spectrum in disease1\n",
    "#Disease 1\n",
    "rootdir = '/home/titli/Documents/test/disease1'\n",
    "for subdir, dirs, files in os.walk(rootdir):\n",
    "    for file in files:\n",
    "        #print (os.path.join(subdir, file))\n",
    "        txt = os.path.join(subdir, file)\n",
    "        x = txt.split(\"/\")\n",
    "        if( x[6] == '1_0-5-1' and x[9] == '980'):\n",
    "            if (str(x[8]) not in patient_array_1):\n",
    "                patient_array_1.append(x[8])\n",
    "                wdfIle = wdfReader(os.path.join(subdir, file))\n",
    "                X, spectra = getspikes(wdfIle) # plotting the spectrum\n",
    "                #if len(spectra)<1015:\n",
    "                #    spectra[len(spectra):len(spectra)+(1015-len(spectra))]=10000\n",
    "                spectra = normalize(spectra)\n",
    "                spectra_array1.append(spectra)\n",
    "spectra_array_1= pd.DataFrame(spectra_array1)\n",
    "labels_test_1 = pd.DataFrame({'labels': np.ones((len(spectra_array1),), dtype=int)})\n",
    "rootdir = '/home/titli/Documents/test/normal'\n",
    "for subdir, dirs, files in os.walk(rootdir):\n",
    "    for file in files:\n",
    "        #print (os.path.join(subdir, file))\n",
    "        txt = os.path.join(subdir, file)\n",
    "        x = txt.split(\"/\")\n",
    "        if( x[6] == '1_0-5-1' and x[9] == '980'):\n",
    "            if (str(x[8]) not in patient_array_0):\n",
    "                patient_array_0.append(x[8])\n",
    "                wdfIle = wdfReader(os.path.join(subdir, file))\n",
    "                X, spectra = getspikes(wdfIle) # plotting the spectrum\n",
    "                #if len(spectra)<1015:\n",
    "                #    spectra[len(spectra):len(spectra)+(1015-len(spectra))]=10000\n",
    "                spectra = normalize(spectra)\n",
    "                spectra_array0.append(spectra)\n",
    "spectra_array_0= pd.DataFrame(spectra_array0)\n",
    "labels_test_0 = pd.DataFrame({'labels': np.zeros((len(spectra_array0),), dtype=int)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "110/110 [==============================] - 0s 1ms/step\n"
     ]
    }
   ],
   "source": [
    "total_df_test = pd.concat([spectra_array_0,spectra_array_1], axis = 0)\n",
    "X_test = total_df_test.values\n",
    "X_test = X_test.reshape(X_test.shape[0],X_test.shape[1],1)\n",
    "labels_df_test = pd.concat([labels_test_0,labels_test_1], axis = 0)\n",
    "y_test = labels_df_test.values\n",
    "y_test = to_categorical(y_test, num_classes=2)\n",
    "model1_test_y = model.predict(X_test, batch_size=10, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/titli/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:1: RuntimeWarning: invalid value encountered in greater\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "/home/titli/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:2: RuntimeWarning: invalid value encountered in less_equal\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "model1_test_y[model1_test_y > 0.5] = 1\n",
    "model1_test_y[model1_test_y <= 0.5] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def F1_score(pred_test_y, actuals):\n",
    "\n",
    "    predictions =[]\n",
    "    true_pos = 0\n",
    "    true_neg = 0\n",
    "    false_pos = 0\n",
    "    false_neg = 0\n",
    "    \n",
    "    for i in range (len(pred_test_y)):\n",
    "        if ((pred_test_y[i,0]==1) & (actuals[i,0]==1)):\n",
    "            true_pos = true_pos+1\n",
    "        elif((pred_test_y[i,0]==0) & (actuals[i,0]==0)):\n",
    "            true_neg = true_neg+1\n",
    "        elif((pred_test_y[i,0]==1) & (actuals[i,0]==0)):\n",
    "            false_pos = false_pos +1\n",
    "        elif((pred_test_y[i,0]==0) & (actuals[i,0]==1)):\n",
    "            false_neg = false_neg+1\n",
    "    prec=true_pos/(true_pos+false_pos)\n",
    "    recall = true_pos/(true_pos+false_neg)\n",
    "    accur=(true_pos+true_neg)/(true_pos+false_pos+ true_neg+ false_neg)\n",
    "    #F1=2*(prec*recall/(prec+recall))\n",
    "    #FPR = false_pos/(false_pos+true_neg)\n",
    "    return (true_pos, false_pos, true_neg, false_neg, accur)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(90, 0, 0, 0, 1.0)\n"
     ]
    }
   ],
   "source": [
    "print((F1_score(model1_test_y, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
