{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://www.kaggle.com/tannistha/hyperparameter-grid-search-with-xgboost/edit\n",
    "#https://github.com/IBM/xgboost-smote-detect-fraud\n",
    "#https://stats.stackexchange.com/questions/179835/how-to-build-a-confusion-matrix-for-a-multiclass-classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/python\n",
    "\n",
    "from __future__ import division\n",
    "\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "import pandas as pd\n",
    "from itertools import product\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn import cross_validation, metrics   #Additional scklearn functions\n",
    "from sklearn.grid_search import GridSearchCV   #Perforing grid search\n",
    "from sklearn.model_selection import KFold\n",
    "from collections import Counter\n",
    "from imblearn.over_sampling import SMOTE \n",
    "from sklearn import decomposition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_spectrum =  pd.read_csv('Spectrum_baseline.csv') #'Spectrum_baseline.csv'\n",
    "labels = pd.read_csv('Spectrum_labels.csv').values\n",
    "labels_new = pd.DataFrame({'Class':labels[:,1].astype('int64')})\n",
    "total_df = pd.concat([data_spectrum, labels_new], axis =1)\n",
    "feature = total_df.columns\n",
    "data = total_df[feature[1:]].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# without last column\n",
    "pca = decomposition.PCA(n_components=200)\n",
    "pca.fit(data[:,:-1])\n",
    "data = pca.transform(data[:,:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_new= np.append(data, total_df.iloc[:,-1].values.reshape(11442,1), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "sz = data_new.shape\n",
    "np.random.shuffle(data_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = data_new[:int(sz[0] * 0.7), :]\n",
    "test = data_new[int(sz[0] * 0.7):, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X = train[:, :200]\n",
    "train_Y = train[:, 200]\n",
    "test_X = test[:, :200]\n",
    "test_Y = test[:, 200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup parameters for xgboost\n",
    "param = {}\n",
    "# use softmax multi-class classification\n",
    "param['objective'] = 'multi:softmax'\n",
    "# scale weight of positive examples\n",
    "param['scale_pos_weight']:[0.33, 0.7, 0.167,0.3,0.4]\n",
    "param['eta'] = 0.1\n",
    "param['max_depth'] = 6\n",
    "param['silent'] = 1\n",
    "param['nthread'] = 4\n",
    "param['num_class'] = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/titli/anaconda3/lib/python3.6/site-packages/xgboost/core.py:614: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  \"because it will generate extra copies and increase memory consumption\")\n"
     ]
    }
   ],
   "source": [
    "sm = SMOTE(random_state=42)\n",
    "X_res, y_res = sm.fit_sample(train_X, train_Y)#ratio={1:1000, 3:1000, 4:1000}\n",
    "X_res, y_res = sm.fit_sample(train_X, train_Y)\n",
    "xg_train = xgb.DMatrix(X_res, label=y_res)\n",
    "xg_test = xgb.DMatrix(test_X, label=test_Y)\n",
    "watchlist = [(xg_train, 'train'), (xg_test, 'test')]\n",
    "num_round = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-merror:0.320382\ttest-merror:0.506263\n",
      "[1]\ttrain-merror:0.293392\ttest-merror:0.492572\n",
      "[2]\ttrain-merror:0.269288\ttest-merror:0.482668\n",
      "[3]\ttrain-merror:0.259097\ttest-merror:0.48092\n",
      "[4]\ttrain-merror:0.241926\ttest-merror:0.468395\n",
      "Test error using softmax = 0.4683949898048354\n"
     ]
    }
   ],
   "source": [
    "bst = xgb.train(param, xg_train, num_round, watchlist)\n",
    "# get prediction\n",
    "pred = bst.predict(xg_test)\n",
    "error_rate = np.sum(pred != test_Y) / test_Y.shape[0]\n",
    "print('Test error using softmax = {}'.format(error_rate))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-merror:0.320382\ttest-merror:0.506263\n",
      "[1]\ttrain-merror:0.293392\ttest-merror:0.492572\n",
      "[2]\ttrain-merror:0.269288\ttest-merror:0.482668\n",
      "[3]\ttrain-merror:0.259097\ttest-merror:0.48092\n",
      "[4]\ttrain-merror:0.241926\ttest-merror:0.468395\n",
      "Test error using softprob = 0.4683949898048354\n"
     ]
    }
   ],
   "source": [
    "# do the same thing again, but output probabilities\n",
    "param['objective'] = 'multi:softprob'\n",
    "bst = xgb.train(param, xg_train, num_round, watchlist)\n",
    "# Note: this convention has been changed since xgboost-unity\n",
    "# get prediction, this is in 1D array, need reshape to (ndata, nclass)\n",
    "pred_prob = bst.predict(xg_test).reshape(test_Y.shape[0], 5)\n",
    "pred_label = np.argmax(pred_prob, axis=1)\n",
    "error_rate = np.sum(pred_label != test_Y) / test_Y.shape[0]\n",
    "print('Test error using softprob = {}'.format(error_rate))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.71280277 0.17035775 0.801      0.30493274 0.31894934] [0.87288136 0.47619048 0.42448331 0.42236025 0.55555556]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(pred, test_Y)\n",
    "recall = np.diag(cm) / np.sum(cm, axis = 1)\n",
    "precision = np.diag(cm) / np.sum(cm, axis = 0)\n",
    "print(recall, precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
